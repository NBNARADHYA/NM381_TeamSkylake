{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kernel uses UNet architecture with ResNet34 encoder, I've used [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) library which has many inbuilt segmentation architectures. This kernel is inspired by [Yury](https://www.kaggle.com/deyury)'s discussion thread [here](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/99440#591985). I've used snippets from multiple other public kernels I've given due credits at the end of this notebook.\n",
    "\n",
    "What's down below?\n",
    "\n",
    "* UNet with imagenet pretrained ResNet34 architecture\n",
    "* Training on 512x512 sized images/masks with Standard Augmentations\n",
    "* MixedLoss (weighted sum of Focal loss and dice loss)\n",
    "* Gradient Accumulution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in ./anaconda3/lib/python3.7/site-packages (0.4.3)\n",
      "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in ./anaconda3/lib/python3.7/site-packages (from albumentations) (0.2.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in ./anaconda3/lib/python3.7/site-packages (from albumentations) (4.1.2.30)\n",
      "Requirement already satisfied: PyYAML in ./anaconda3/lib/python3.7/site-packages (from albumentations) (5.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in ./anaconda3/lib/python3.7/site-packages (from albumentations) (1.16.2)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.7/site-packages (from albumentations) (1.2.1)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.12.0)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in ./anaconda3/lib/python3.7/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.14.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in ./anaconda3/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.0.2)\n",
      "Requirement already satisfied: dask[array]>=1.0.0 in ./anaconda3/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.4)\n",
      "Requirement already satisfied: networkx>=1.8 in ./anaconda3/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.2)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in ./anaconda3/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.8.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in ./anaconda3/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.3)\n",
      "Requirement already satisfied: pillow>=4.3.0 in ./anaconda3/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in ./anaconda3/lib/python3.7/site-packages (from dask[array]>=1.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.9.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./anaconda3/lib/python3.7/site-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.0)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (40.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "For encoding and decoding RLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode(rle, height=1024, width=1024, fill_value=1):\n",
    "    component = np.zeros((height, width), np.float32)\n",
    "    component = component.reshape(-1)\n",
    "    rle = np.array([int(s) for s in rle.strip().split(' ')])\n",
    "    rle = rle.reshape(-1, 2)\n",
    "    start = 0\n",
    "    for index, length in rle:\n",
    "        start = start+index\n",
    "        end = start+length\n",
    "        component[start: end] = fill_value\n",
    "        start = end\n",
    "    component = component.reshape(width, height).T\n",
    "    return component\n",
    "\n",
    "def run_length_encode(component):\n",
    "    component = component.T.flatten()\n",
    "    start = np.where(component[1:] > component[:-1])[0]+1\n",
    "    end = np.where(component[:-1] > component[1:])[0]+1\n",
    "    length = end-start\n",
    "    rle = []\n",
    "    for i in range(len(length)):\n",
    "        if i == 0:\n",
    "            rle.extend([start[0], length[0]])\n",
    "        else:\n",
    "            rle.extend([start[i]-end[i-1], length[i]])\n",
    "    rle = ' '.join([str(r) for r in rle])\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "Pytorch custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkyfinderDataset(Dataset):\n",
    "    def __init__(self, df, size, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.size = size\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, size, mean, std)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df['image'].iloc[idx]\n",
    "        mask_path = self.df['mask'].iloc[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = mask[:,:,0]\n",
    "        augmented = self.transforms(image=image, mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "def get_transforms(phase, size, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "#                 HorizontalFlip(),\n",
    "                ShiftScaleRotate(\n",
    "                    shift_limit=0,  # no resizing\n",
    "                    scale_limit=0.1,\n",
    "                    rotate_limit=10, # rotate\n",
    "                    p=0.5,\n",
    "                    border_mode=cv2.BORDER_CONSTANT\n",
    "                ),\n",
    "#                 GaussNoise(),\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Resize(size, size),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    fold,\n",
    "    total_folds,\n",
    "    df_path,\n",
    "    phase,\n",
    "    size,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df = df.sample(frac=0.2)\n",
    "    kfold = StratifiedKFold(total_folds, shuffle=True, random_state=69)\n",
    "    train_idx, val_idx = list(kfold.split(df[\"image\"], df[\"mask\"]))[fold]\n",
    "    train_df, val_df = df.iloc[train_idx], df.iloc[val_idx]\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    # NOTE: total_folds=5 -> train/val : 80%/20%\n",
    "    \n",
    "    image_dataset = SkyfinderDataset(df,size, mean, std, phase)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = provider(\n",
    "    fold=0,\n",
    "    total_folds=5,\n",
    "    df_path=\"/home/rath772k/sample.csv\",\n",
    "    phase=\"train\",\n",
    "    size=512,\n",
    "    mean = (0.485, 0.456, 0.406),\n",
    "    std = (0.229, 0.224, 0.225),\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
